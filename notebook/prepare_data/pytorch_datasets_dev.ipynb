{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src import ROOT_DIR\n",
    "from src.datasets import MixedDatasetPreprocessing, BildacherBackgroundDataset, OUT_IMAGE_RES, TRAIN_VAL_SPLIT, SEED, DATA_DIR\n",
    "from src.utils import (\n",
    "    is_bbox_outside_crop,\n",
    "    get_patch_label,\n",
    "    plot_tensor,\n",
    "    unpack_yolo_label,\n",
    "    yolo_bbox_relative_to_absolute_coords,\n",
    "    )\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MixedDatasetPreprocessing(center_crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.transforms.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label, patch = dataset[1]\n",
    "image.shape, label, patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, label.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, w, h = unpack_yolo_label(label[1])\n",
    "x, y, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tensor(image)\n",
    "H = image.shape[1]\n",
    "W = image.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_height = round(h * H)\n",
    "patch_width = round(w * W)\n",
    "patch_height, patch_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_center = round(x * W)\n",
    "y_center = round(y * H)\n",
    "_patch = image[:, y_center - patch_height//2 : y_center + patch_height//2, x_center - patch_width//2 : x_center + patch_width//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_patch.shape)\n",
    "plot_tensor(_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pil_to_tensor(patch).shape)\n",
    "patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Patch extracted from labels match! (before doing CenterCrop)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discard labels, patches and images when any part of the BBox is outside CenterCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MixedDatasetPreprocessing(center_crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.images) == len(dataset.labels) == len(dataset.patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.patches_idxs_to_discard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.       , 0.9036328, 0.9363663, 0.1510937, 0.1277362],\n",
       "       [0.       , 0.884458 , 0.5364212, 0.0780175, 0.1018095],\n",
       "       [0.       , 0.7046386, 0.2098388, 0.0486718, 0.1118827],\n",
       "       [0.       , 0.6617773, 0.3876007, 0.042207 , 0.0393333],\n",
       "       [0.       , 0.3827685, 0.3029743, 0.0924121, 0.0902564]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label, patch = dataset[1]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Test -> seems to work\n",
    "# for i in range(len(dataset)):\n",
    "#     image, label, patch = dataset[i]\n",
    "#     patch_height, patch_width = pil_to_tensor(patch).shape[1:]\n",
    "#     H, W = image.shape[1], image.shape[2]\n",
    "#     label_match = get_patch_label(image, label, patch)\n",
    "#     x, y, w, h = unpack_yolo_label(label_match)\n",
    "#     x, y, w, h = yolo_bbox_relative_to_absolute_coords(x, y, w, h, W, H)\n",
    "#     print(h, w)\n",
    "#     print(patch_height, patch_width)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patches_to_discard = []\n",
    "# labels = []\n",
    "# for i in tqdm(range(len(dataset))):\n",
    "#     image, label, patch = dataset[i]\n",
    "    \n",
    "#     # There are more than one bbox per image, we need to find which one is the one that we see in the patch\n",
    "#     # Finding closest match by patch size:  \n",
    "#     patch_height, patch_width = pil_to_tensor(patch).shape[1:]\n",
    "#     H, W = image.shape[1], image.shape[2]\n",
    "#     label_match = get_patch_label(image, label, patch)\n",
    "#     labels.append(label_match)\n",
    "    \n",
    "#     ## BBox coordinates\n",
    "#     x, y, w, h = unpack_yolo_label(label_match)\n",
    "#     x, y, w, h = yolo_bbox_relative_to_absolute_coords(x, y, w, h, W, H)\n",
    "#     if is_bbox_outside_crop(x, y, w, h, W, H, OUT_IMAGE_RES):\n",
    "#         patches_to_discard.append(i)\n",
    "        \n",
    "# patches_to_discard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(dataset))\n",
    "train, val = train_test_split(indices, train_size=TRAIN_VAL_SPLIT, random_state=SEED)\n",
    "print(len(train) + len(val) + len(dataset.patches_idxs_to_discard))\n",
    "train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(DATA_DIR.parent / 'postprocessed' / split).mkdir(parents=True, exist_ok=True) for split in [\"train\", \"val\", \"free_patches\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3271"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_dir = dataset.dataset_dir / 'images'\n",
    "labels_dir = dataset.dataset_dir / 'yolo'\n",
    "patches_dir = DATA_DIR / 'patches'\n",
    "len([path for path in patches_dir.iterdir() if ])\n",
    "\n",
    "# Get paths fro train and val sets from self.images, self.labels and self.patches. Get paths for free_patches from patches to discard and a self._patches attribute "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bildacher backgrounds dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bildacher = BildacherBackgroundDataset()\n",
    "image = bildacher[0]\n",
    "print(image.shape)\n",
    "plot_tensor(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
