{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook\n",
    "\n",
    "Image blending:\n",
    "- Overlaying\n",
    "- Linear blending\n",
    "- Overlaying + gaussian filter\n",
    "- Linear blending + cv inpaint\n",
    "- Overlaying + HuggingFace inpainting\n",
    "- Overlaying + Dall-e 2 inpainting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbe7d25-299f-4f58-9ded-30c0bee80055",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionInpaintPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(\n",
    "    patch: np.array, \n",
    "    background: np.array, \n",
    "    output: np.array,\n",
    "    zoom: tuple[tuple[int, int]],\n",
    "    method_name: str\n",
    "):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    axes[0].imshow(patch)\n",
    "    axes[0].set_title(\"Patch\")\n",
    "    axes[1].imshow(background)\n",
    "    axes[1].set_title(\"Background\")\n",
    "    axes[2].imshow(output)\n",
    "    axes[2].set_title(\"Merged images\")\n",
    "    axes[3].imshow(output[\n",
    "        zoom[1][0]:zoom[1][1],\n",
    "        zoom[0][0]:zoom[0][1],\n",
    "        :\n",
    "    ])\n",
    "    axes[3].set_title(\"Zoomed\")\n",
    "    # axes[3].set_xlim(zoom[0])\n",
    "    # axes[3].set_ylim(zoom[1])\n",
    "    plt.suptitle(method_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data/postprocessed\"\n",
    "\n",
    "BORDER = 20 # in pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49382e2-4f36-475c-8ace-a217c6058259",
   "metadata": {},
   "source": [
    "# Load example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_path = os.path.join(\n",
    "    DATA_DIR,\n",
    "    \"train\",\n",
    "    \"patches\",\n",
    "    \"20220816_TaenikonWiese_S_xx_F_xx_O_sama_ID2_DJI_20220816121514_0132.0_2_rumex.png\"\n",
    ")\n",
    "easy_background_path = os.path.join(\n",
    "    DATA_DIR,\n",
    "    \"train\",\n",
    "    \"images\",\n",
    "    \"20230615_SchildDotnachtZaelgli_S_20_F_60_H_12_O_krma_ID1_DJI_20230615145252_0193.1_3.png\"\n",
    ")\n",
    "difficult_background_path = os.path.join(\n",
    "    DATA_DIR,\n",
    "    \"train\",\n",
    "    \"images\",\n",
    "    \"20230609_HerrenpuentSuedost_S_20_F_60_H_12_O_krma_ID1_DJI_20230609151113_0028.1_3.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"difficult\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_path = easy_background_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20464e6e-b855-49f3-b5eb-23a2a4f8643f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "patch = cv.imread(patch_path)\n",
    "patch = cv.cvtColor(patch, cv.COLOR_RGB2BGR)\n",
    "background = cv.imread(background_path)\n",
    "background = cv.cvtColor(background, cv.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background must be a square for some of the methods we are trying\n",
    "background = background[:512, :512, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe3c72c-fa3b-4209-99a3-10b3acc91cbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure the patch is small in comparison to the background image\n",
    "bg_y, bg_x, _ = background.shape\n",
    "# scaling = 0.2\n",
    "# patch = cv.resize(patch, (int(bg_x * scaling), int(bg_y * scaling)))\n",
    "p_x, p_y, _ = patch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e843e8-b321-473a-af45-0e34632a7692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select an area in the background where we want to add the patch\n",
    "x, y = 50, 50\n",
    "x_min, x_max = x, x+p_x\n",
    "y_min, y_max = y, y+p_y\n",
    "bg_patch = background[x_min:x_max, y_min:y_max, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed1e0ae-f09d-4d77-bc88-1288d3def7d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert bg_patch.shape == patch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZOOM = ((y_min-BORDER, y_max+BORDER), (x_min-BORDER, x_max+BORDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_box_mask = np.zeros(background.shape[:-1])\n",
    "bounding_box_mask[x_min:x_max, y_min:y_max] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlaying patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add blended images pack into the background\n",
    "background_overlay = background.copy()\n",
    "background_overlay[x_min:x_max, y_min:y_max, :] = patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_name = \"Simple Overlaying\"\n",
    "show_result(\n",
    "    patch, \n",
    "    background,\n",
    "    background_overlay, \n",
    "    zoom=ZOOM,\n",
    "    method_name=method_name\n",
    ")\n",
    "plt.savefig(f\"{method_name.replace(' ', '_')}_{suffix}.png\", dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057a4873-e58f-4542-8f96-02b975d5cfb1",
   "metadata": {},
   "source": [
    "# Linear blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd209ee-0f69-423f-a573-5cd0274ba3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Blend patch and subset of background\n",
    "alpha = 0.7\n",
    "beta = 1 - alpha\n",
    "dst = cv.addWeighted(patch, alpha, bg_patch, beta, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7477bbd9-e2a3-4b7c-a011-2b59848d600b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add blended images pack into the background\n",
    "background_linear_blend = background.copy()\n",
    "background_linear_blend[x:x+p_x, y:y+p_y, :] = dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_name=\"Linear Blending\"\n",
    "show_result(\n",
    "    patch, \n",
    "    background, \n",
    "    background_linear_blend, \n",
    "    zoom=ZOOM,\n",
    "    method_name=method_name\n",
    ")\n",
    "plt.savefig(f\"{method_name.replace(' ', '_')}_{suffix}.png\", dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd2ab98-6664-4330-a023-94a629f984a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Overlay + Gaussian blur\n",
    "\n",
    "- Blurring edges of overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask is essentially the border around the patch\n",
    "border = int(0.2 * min(p_x, p_y))  # in pixel\n",
    "mask = np.zeros((p_x+2*border, p_y+2*border))\n",
    "mask[:2*border, :] = 1\n",
    "mask[-2*border:, :] = 1\n",
    "mask[:, -2*border:] = 1\n",
    "mask[:, :2*border] = 1\n",
    "\n",
    "tmp = np.zeros((bg_y, bg_x))\n",
    "tmp[x-border:x+p_x+border, y-border:y+p_y+border] = mask\n",
    "mask = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert mask to 3D mask\n",
    "mask_3d = np.dstack((mask, mask, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_image = (mask_3d * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfda7a8-f971-4c00-bfc6-749bb9048bc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "border_smoothed = cv.GaussianBlur(\n",
    "    background_overlay,\n",
    "    (0, 0),\n",
    "    sigmaX=1,\n",
    "    sigmaY=1,\n",
    "    borderType=cv.BORDER_DEFAULT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dbfd49-574d-47a5-9a3d-a62692729583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add blended images pack into the background\n",
    "background_overlay_blurred = background_overlay.copy()\n",
    "for i in range(background_overlay_blurred.shape[0]):\n",
    "    for j in range(background_overlay_blurred.shape[1]):\n",
    "        if mask[i, j]:\n",
    "            background_overlay_blurred[i, j] = border_smoothed[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_name=\"Overlaying and Gaussian Smoothing\"\n",
    "show_result(\n",
    "    patch, \n",
    "    background, \n",
    "    background_overlay_blurred, \n",
    "    zoom=ZOOM,\n",
    "    method_name=method_name\n",
    ")\n",
    "plt.savefig(f\"{method_name.replace(' ', '_')}_{suffix}.png\", dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d0bd07-8df4-4713-804f-5576c6232450",
   "metadata": {},
   "source": [
    "# Linear blending + Inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d722b284-4014-4bc3-b866-accdb3f6990c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "background_inpaint = cv.inpaint(background_overlay, mask.astype(np.uint8), 3, cv.INPAINT_NS) # cv.INPAINT_TELEA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f65fba-a399-4a31-8f05-b7d328fd73da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "method_name=\"Overlay + Simple Inpaint\"\n",
    "show_result(\n",
    "    patch, \n",
    "    background, \n",
    "    background_inpaint, \n",
    "    zoom=ZOOM,\n",
    "    method_name=method_name\n",
    ")\n",
    "plt.savefig(f\"{method_name.replace(' ', '_')}_{suffix}.png\", dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcbc8fc-ed91-4f38-89d3-1ffdf3797761",
   "metadata": {},
   "source": [
    "# Huggingface inpainting\n",
    "\n",
    "https://huggingface.co/runwayml/stable-diffusion-inpainting\n",
    "\n",
    "**Note**:\n",
    "- Changes image scale => need to identify location of mask based on scaling..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "vis = background_overlay.copy()\n",
    "vis_ = vis.copy()\n",
    "for i in range(vis_.shape[0]):\n",
    "    for j in range(vis_.shape[1]):\n",
    "        vis_[i, j] = vis[i, j] if mask[i, j] == 0 else 1\n",
    "\n",
    "ax[0].imshow(vis)\n",
    "ax[0].set_xlim(*ZOOM[0])\n",
    "ax[0].set_ylim(*ZOOM[1])\n",
    "ax[1].imshow(vis_)\n",
    "ax[1].set_xlim(*ZOOM[0])\n",
    "ax[1].set_ylim(*ZOOM[1])\n",
    "\n",
    "mask_image = (mask_3d * 255).astype(np.uint8)\n",
    "fig, ax = plt.subplots()\n",
    "cs = plt.imshow(mask_image)\n",
    "fig.colorbar(cs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-inpainting\",\n",
    "    # revision=\"fp16\",\n",
    "    # torch_dtype depends on CPU (float32) vs GPU (float16)\n",
    "    # https://stackoverflow.com/questions/75641074/i-run-stable-diffusion-its-wrong-runtimeerror-layernormkernelimpl-not-implem\n",
    "    # torch_dtype=torch.float16,\n",
    ").to(\"cuda\")\n",
    "# Image and mask_image should be PIL images.\n",
    "# The mask structure is white for in-painting and black for keeping as is\n",
    "image = pipe(\n",
    "    prompt=\"\", \n",
    "    image=Image.fromarray(background_overlay),\n",
    "    mask_image=Image.fromarray(mask_image)\n",
    ").images[0]\n",
    "image.save(os.path.join(DATA_DIR, \"output_huggingface.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_huggingface = cv.imread(os.path.join(DATA_DIR, \"output_huggingface.jpg\"), cv.IMREAD_COLOR)\n",
    "background_huggingface = cv.cvtColor(background_huggingface, cv.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_name = \"Overlay HuggingFace Inpaint\"\n",
    "show_result(\n",
    "    patch,\n",
    "    background,\n",
    "    background_huggingface,\n",
    "    zoom=ZOOM,\n",
    "    method_name=method_name\n",
    ")\n",
    "plt.savefig(f\"{method_name.replace(' ', '_')}_{suffix}.png\", dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI, OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = AzureOpenAI(\n",
    "#     api_version=\"2023-12-01-preview\",\n",
    "#     azure_endpoint=\"https://sdsc-hackathon-alpine-aster-13.openai.azure.com/\",\n",
    "#     api_key=\"977a2326c8c547b98666e6d88ed61c40\",\n",
    "#     azure_deployment=\"dall-e-3\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = client.images.generate(\n",
    "#     model=\"dall-e-3\", # the name of your DALL-E 3 deployment\n",
    "#     prompt=\"Clouds\",\n",
    "#     n=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For convenience, write images to disk and read them in the call\n",
    "cv.imwrite(os.path.join(DATA_DIR, \"input_dalle_image.png\"), cv.cvtColor(background_overlay, cv.COLOR_RGB2BGR))\n",
    "cv.imwrite(os.path.join(DATA_DIR, \"input_dalle_image.jpg\"), cv.cvtColor(background_overlay, cv.COLOR_RGB2BGR))\n",
    "img_mask = cv.threshold(mask_3d, 0.9, 255, cv.THRESH_BINARY)[1]\n",
    "cv.imwrite(os.path.join(DATA_DIR, \"input_dalle_mask.png\"), img_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.images.edit(\n",
    "    model=\"dall-e-2\",\n",
    "    image=open(os.path.join(DATA_DIR, \"input_dalle_image.png\"), \"rb\"),\n",
    "    mask=open(os.path.join(DATA_DIR, \"input_dalle_mask.png\"), \"rb\"),\n",
    "    prompt=\"Please perform content aware filling\",\n",
    "    n=1,\n",
    "    size=\"512x512\"\n",
    ")\n",
    "image_url = response.data[0].url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(os.path.join(DATA_DIR, \"output_huggingface.jpg\"), cv.IMREAD_COLOR)\n",
    "img = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
